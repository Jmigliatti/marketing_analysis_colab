# -*- coding: utf-8 -*-
"""marketing_analysis_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f0Gdz0AePvEJ-3NoWdDxKHaOLOBAWbzL

# An√°lise de Campanha de Marketing de Vinhos
Este notebook realiza a limpeza e an√°lise dos dados. Al√©m de criar modelos preditivos para a aceita√ß√£o da oferta da pr√≥xima campanha.
"""

# Instalar bibliotecas necess√°rias (se estiver rodando localmente)
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Configura√ß√µes visuais
sns.set(style="whitegrid")

"""## Carregamento dos dados
carregamento via upload do arquivo e exibi√ß√£o da tabela que foi gerada
"""

# Fazer upload do arquivo Excel
from google.colab import files
uploaded = files.upload()

# Ler o arquivo Excel
xls = pd.ExcelFile(next(iter(uploaded)))
print("Planilhas dispon√≠veis:", xls.sheet_names)

# Carregar a planilha 'data'
df = xls.parse('data')

# Visualizar as primeiras linhas
df.head()

"""##Detec√ß√£o de dados nulos"""

# Verificar se h√° valores ausentes restantes
df.isnull().sum().sort_values(ascending=False).head()

"""##Excluir os objetos com valores nulos
Decidi excluir os objetos com valores nulos, pois, como havia apenas 24 objetos nulos em um total de 2.240, √© razo√°vel supor que essa exclus√£o n√£o afetar√° significativamente a an√°lise dos dados nem a constru√ß√£o dos modelos preditivos.
"""

# Converter a coluna de datas e remover valores ausentes em 'Income'
df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], errors='coerce', dayfirst=True)
df = df.dropna(subset=['Income'])

# Verificar se h√° valores ausentes restantes
df.isnull().sum().sort_values(ascending=False).head()

"""##Verificar quais s√£o os tipos de dados presentes em cada coluna"""

# Verificar tipos de dados
df.dtypes

"""##Detec√ß√£o de Outliers
A detec√ß√£o de outliers √© importante, pois os outliers s√£o dados que fogem do padr√£o do grupo e podem atrapalhar a an√°lise.
"""

fig, ax = plt.subplots(figsize=(15, 10))

df.boxplot(ax=ax)

plt.show()

plt.boxplot(df['Income'])
plt.show()

"""Outliers detectados na coluna Income"""

# Calculo do IQR
quartil1 = df['Income'].quantile(0.25)
quartil3 = df['Income'].quantile(0.75)
InterQuartil = quartil3 - quartil1

# Identificando os outliers
outliers = df[(df['Income'] < (quartil1 - 1.5 * InterQuartil)) | (df['Income'] > (quartil3 + 1.5 * InterQuartil))]

# Imprime o n√∫mero de outliers
print("N√∫mero de outliers na coluna Income:", len(outliers))

"""##Remo√ß√£o dos Outliers detectados
Esse c√≥digo remove os valores de 'Income' que est√£o muito abaixo ou muito acima do esperado, baseando-se no intervalo interquartil.

"""

# Remove os outlier da coluna
df = df[~((df['Income'] < (quartil1 - 1.5 * InterQuartil)) | (df['Income'] > (quartil3 + 1.5 * InterQuartil)))]

plt.boxplot(df['Income'])
plt.show()

distribuicao = df['Response'].value_counts()
print("Distribui√ß√£o das classes:\n", distribuicao)

"""#Engenharia de Features
Realizei uma etapa de engenharia de features com o objetivo de enriquecer o conjunto de dados e facilitar a an√°lise do perfil e do comportamento dos clientes. As novas vari√°veis criadas foram:

- Age: calculada a partir do ano de nascimento, representa a idade atual do cliente (em 2025). Essa informa√ß√£o √© importante para entender como diferentes faixas et√°rias se comportam em rela√ß√£o ao consumo.

- Total_Kids: soma do n√∫mero de crian√ßas e adolescentes em casa, o que pode indicar o tipo de consumo familiar e o potencial de gastos com determinados produtos.

- Total_Spent: total gasto pelo cliente em diferentes categorias de produtos. Essa vari√°vel resume o comportamento de consumo e pode ajudar a identificar clientes mais rent√°veis.

- Customer_Days: tempo em dias desde o primeiro registro como cliente at√© 1¬∫ de janeiro de 2025. Essa vari√°vel permite avaliar a fidelidade e o ciclo de vida do cliente.

Essas novas features s√£o fundamentais para aprofundar a an√°lise explorat√≥ria, segmentar melhor os consumidores e desenvolver modelos preditivos mais precisos. Elas ajudam a capturar aspectos importantes do comportamento dos clientes que n√£o estavam diretamente dispon√≠veis nos dados originais.
"""

# Criar coluna de idade
df['Age'] = 2025 - df['Year_Birth']

# Total de filhos em casa
df['Total_Kids'] = df['Kidhome'] + df['Teenhome']

# Total gasto em produtos
df['Total_Spent'] = df[['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']].sum(axis=1)

# Tempo como cliente (em dias)
df['Customer_Days'] = (pd.to_datetime('2025-01-01') - df['Dt_Customer']).dt.days

"""##Descri√ß√£o das novas features
A fun√ß√£o describe() foi utilizada para gerar uma an√°lise estat√≠stica descritiva das novas vari√°veis criadas durante a engenharia de features. Com ela, √© poss√≠vel obter informa√ß√µes como m√©dia, desvio padr√£o, valores m√≠nimo e m√°ximo, al√©m dos quartis de cada feature:

- Age: permite identificar a faixa et√°ria predominante entre os clientes, bem como varia√ß√µes extremas (clientes muito jovens ou muito velhos).

- Total_Kids: revela a distribui√ß√£o do n√∫mero de filhos em casa, ajudando a entender o perfil familiar dos consumidores.

- Total_Spent: mostra quanto, em m√©dia, os clientes gastam e quais s√£o os limites inferior e superior de consumo. Isso pode ser √∫til para identificar grandes compradores e poss√≠veis outliers.

Customer_Days: indica h√° quanto tempo, em dias, cada pessoa √© cliente da empresa. A an√°lise dessa vari√°vel pode ajudar a entender a fidelidade dos clientes e padr√µes de comportamento ao longo do tempo.
"""

# Descri√ß√£o das novas features
df[['Age', 'Total_Kids', 'Total_Spent', 'Customer_Days']].describe()

"""##Interpreta√ß√£o Geral das Features Criadas
1. Age (Idade)
M√©dia: 56 anos ‚Äî a maior parte dos clientes est√° na faixa da meia-idade.
- M√≠nimo / M√°ximo: de 29 a 132 anos ‚Äî esse valor m√°ximo √© provavelmente um outlier ou erro de digita√ß√£o, pois ultrapassa a expectativa de vida humana.
- Distribui√ß√£o: concentrada entre 48 e 66 anos (25%‚Äì75%), ou seja, o p√∫blico predominante est√° na faixa de adultos maduros e idosos jovens.

2. Total_Kids (Total de filhos em casa)
M√©dia: Aproximadamente 0,95 ‚Äî a maioria dos clientes tem entre 0 e 1 filho em casa.

- M√°ximo: 3 filhos ‚Äî valor relativamente baixo, o que indica lares pequenos.

- Distribui√ß√£o: 75% dos clientes t√™m no m√°ximo 1 filho em casa, e 25% n√£o t√™m nenhum.

3. Total_Spent (Total gasto em produtos)
M√©dia: 606 ‚Äî esse √© o valor m√©dio de gastos somando todos os produtos.

- M√≠nimo: 5 ‚Äî indica a presen√ßa de clientes com pouqu√≠ssimo consumo.

- M√°ximo: 2525 ‚Äî representa grandes consumidores, o que pode indicar clientes de alto valor.

- Distribui√ß√£o: a mediana √© de 397, e 75% dos clientes gastam at√© 1047, mostrando assimetria positiva (alguns clientes gastam muito mais que a m√©dia).

4. Customer_Days (Tempo como cliente em dias)
M√©dia: 4190 dias (11,5 anos) ‚Äî mostra uma base de clientes fiel, com longa rela√ß√£o com a empresa.

- Intervalo: de 3679 a 4742 dias ‚Äî todos os clientes est√£o com a empresa h√° pelo menos 10 anos, o que indica um recorte de base bastante consolidada.

- Desvio padr√£o baixo: mostra que os tempos como cliente s√£o bem distribu√≠dos de forma consistente.

#An√°lise Explorat√≥ria
##An√°lise da distribui√ß√£o de Renda
A maior parte dos clientes possui renda entre 30.000 e 80.000, com picos de frequ√™ncia em torno de 40.000 a 70.000.
"""

sns.histplot(df['Income'], bins=10, kde=True)
plt.title('Distribui√ß√£o de Renda')
plt.xlabel('Renda')
plt.ylabel('Contagem')
plt.show()

"""##An√°lise da Distribui√ß√£o de Idade
A maior parte dos clientes est√° concentrada entre 40 e 70 anos, com pico de frequ√™ncia por volta dos 50 a 55 anos. A curva tem uma cauda mais alongada √† direita, o que indica a presen√ßa de clientes mais velhos, embora em menor n√∫mero.
"""

# Distribui√ß√£o da Idade
plt.figure(figsize=(8,4))
sns.histplot(df['Age'], bins=30, kde=True)
plt.title('Distribui√ß√£o de Idade')
plt.xlabel('Idade')
plt.ylabel('Contagem')
plt.show()

"""##Total de Gastos x Resposta √† Campanha
1. Maior Gasto entre Clientes que Aceitaram a Campanha (Resposta = 1):
A mediana (linha central da caixa) dos clientes que responderam positivamente √† campanha √© significativamente mais alta que a dos que n√£o responderam. Isso indica que clientes mais engajados tendem a gastar mais.

2. Clientes que responderam "Sim" apresentam uma faixa de gasto mais ampla, indo de cerca de 0 at√© mais de ‚Ç¨2500, com v√°rios clientes gastando bem acima da m√©dia. J√° entre os que responderam "N√£o", os gastos s√£o mais concentrados entre ‚Ç¨0 e ‚Ç¨1000, com alguns outliers acima de ‚Ç¨2000.


"""

# Boxplot: Total gasto vs. resposta √† campanha
plt.figure(figsize=(8,4))
sns.boxplot(x='Response', y='Total_Spent', data=df)
plt.title('Total Gasto x Resposta √† Campanha')
plt.xlabel('Resposta (0 = N√£o, 1 = Sim)')
plt.ylabel('Total Gasto (‚Ç¨)')
plt.show()

"""#Cria√ß√£o de Modelos Preditivos
Para prever a vari√°vel alvo Response (indicando se o cliente aceitou a campanha), foram testados tr√™s modelos principais: Random Forest Classifier, XGBoost e Regress√£o Log√≠stica.

Inicialmente, o conjunto de dados foi preparado com tratamento de valores ausentes, remo√ß√£o de outliers, transforma√ß√£o de vari√°veis categ√≥ricas por one-hot encoding e normaliza√ß√£o das vari√°veis num√©ricas. Devido ao desbalanceamento da vari√°vel alvo, foram utilizados recursos como class_weight='balanced' e an√°lise de m√©tricas espec√≠ficas (como o recall da classe minorit√°ria).

Os modelos foram avaliados com matriz de confus√£o, relat√≥rio de classifica√ß√£o e interpreta√ß√£o dos coeficientes, permitindo compara√ß√µes claras entre desempenho e interpretabilidade.

##Padroniza√ß√£o de Vari√°veis Categ√≥ricas
Antes da codifica√ß√£o das vari√°veis categ√≥ricas, foi realizada uma etapa de padroniza√ß√£o dos valores presentes em Marital_Status, visando agrupar categorias similares ou irrelevantes para reduzir a dispers√£o e aumentar a consist√™ncia dos dados.

Algumas categorias continham valores pouco representativos ou que poderiam ser agrupados de maneira sem√¢ntica:

- As categorias 'Alone', 'Absurd' e 'YOLO' foram agrupadas como 'Single', representando pessoas solteiras ou n√£o casadas.

- As categorias 'Divorced' e 'Widow' foram consolidadas como 'Separated', representando pessoas que n√£o est√£o mais em um relacionamento conjugal ativo.

Essa simplifica√ß√£o ajudou a reduzir o n√∫mero de categorias distintas e a evitar sparsidade excessiva durante o processo de one-hot encoding. Ap√≥s o tratamento, a distribui√ß√£o das categorias em Marital_Status e Education foi verificada para garantir que os agrupamentos mantiveram a coer√™ncia e n√£o comprometeram a representatividade dos dados.
"""

# Etapa 1: Padroniza√ß√£o dos valores em 'Marital_Status'
df['Marital_Status'] = df['Marital_Status'].replace({
    'Alone': 'Single',
    'Absurd': 'Single',
    'YOLO': 'Single',
    'Divorced': 'Separated',
    'Widow': 'Separated'
})

# Verificando os valores √∫nicos ap√≥s limpeza
print(df['Marital_Status'].value_counts())
print(df['Education'].value_counts())

"""##Codifica√ß√£o de Vari√°veis Categ√≥ricas (One-Hot Encoding)
Ap√≥s a padroniza√ß√£o dos valores nas vari√°veis categ√≥ricas, foi aplicada a t√©cnica de One-Hot Encoding para converter as vari√°veis n√£o num√©ricas em um formato adequado para algoritmos de machine learning.

As vari√°veis selecionadas para codifica√ß√£o foram:

- Education

- Marital_Status
"""

# Etapa 2: One-Hot Encoding das vari√°veis categ√≥ricas
categorical_vars = ['Education', 'Marital_Status']
df_encoded = pd.get_dummies(df, columns=categorical_vars, drop_first=True)

# Verificando colunas ap√≥s encoding
df_encoded.columns

"""##An√°lise de Correla√ß√£o com a Vari√°vel Alvo
Foi realizada uma an√°lise de correla√ß√£o entre a vari√°vel alvo Response e as vari√°veis num√©ricas do conjunto de dados, com o objetivo de identificar quais atributos apresentavam maior associa√ß√£o linear com a resposta dos clientes.

Utilizando a fun√ß√£o .corr() do pandas com o par√¢metro numeric_only=True, foi poss√≠vel gerar uma matriz de correla√ß√£o filtrada para os dados quantitativos. Em seguida, os valores foram ordenados de forma decrescente para destacar os atributos mais correlacionados positivamente com a vari√°vel de interesse.
"""

correlations_post_encoding = df_encoded.corr(numeric_only=True)['Response'].sort_values(ascending=False)
print(correlations_post_encoding.head(20))  # Top 20 mais correlacionadas

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
sns.heatmap(df_encoded.corr(numeric_only=True)[['Response']].sort_values(by='Response', ascending=False), annot=True)
plt.title("Correla√ß√£o com Response (p√≥s-tratamento)")
plt.show()

"""##Sele√ß√£o de Features e classe alvo
Esta c√©lula define as features (vari√°veis preditoras) e o target (vari√°vel resposta) que ser√£o utilizados no modelo preditivo. As features com maior correla√ß√£o com a classe alvo foram selecionadas para a previs√£o.


"""

selected_features = [
    'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5',
    'Total_Spent', 'MntWines', 'MntMeatProducts', 'MntGoldProds',
    'MntFruits', 'MntSweetProducts', 'MntFishProducts',
    'NumCatalogPurchases', 'NumWebPurchases',
    'Customer_Days', 'Income',
    'Marital_Status_Single'
]

X = df_encoded[selected_features]
y = df_encoded['Response']

"""##Cria√ß√£o dos splits de treino/testes
Fiz uma divis√£o 80% dos obejtos para treino e 20% para testes
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

"""##Modelo classificador Random Forest
Cria√ß√£o e treinamento do classificador Random Forest
"""

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

"""##Avalia√ß√£o do Random Forest
Este bloco avalia o desempenho do classificador atrav√©s de algumas m√©tricas
"""

from sklearn.metrics import classification_report, confusion_matrix

# Matriz de Confus√£o
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title("Matriz de Confus√£o - Classificador Random Forest")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.show()
print("\nRelat√≥rio de Classifica√ß√£o:\n", classification_report(y_test, y_pred))

"""##Interpreta√ß√£o dos Resultados do Classificador Random Forest
###Matriz de Confus√£o
- Verdadeiros Negativos (TN): 373 ‚Äî Clientes corretamente identificados como n√£o propensos a responder √† campanha.

- Falsos Positivos (FP): 4 ‚Äî Clientes identificados como propensos a responder, mas que na verdade n√£o responderam √† campanha.

- Falsos Negativos (FN): 46 ‚Äî Clientes que responderiam √† campanha, mas foram classificados como n√£o responsivos.

- Verdadeiros Positivos (TP): 21 ‚Äî Clientes corretamente identificados como propensos a responder √† campanha.

###Outras M√©tricas
- Acur√°cia geral: 0.89 ‚Üí O modelo acerta 89% das previs√µes.

- Recall da classe 1 (0.31): O modelo detecta apenas 31% dos clientes que realmente responderiam ‚Äî um desempenho limitado para campanhas onde o objetivo √© maximizar convers√µes.

- Precision da classe 1 (0.84): Quando o modelo prev√™ que algu√©m ir√° responder, ele est√° certo 84% das vezes ‚Äî o que √© bom, mas insuficiente se o recall for baixo.

- F1-score da classe 1 (0.46): Baixo equil√≠brio entre precis√£o e recall na identifica√ß√£o de clientes responsivos.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

importances = pd.Series(model.feature_importances_, index=X.columns)
importances.sort_values().tail(10).plot(kind='barh')
plt.title('Top 10 vari√°veis mais importantes')
plt.xlabel('Import√¢ncia')
plt.tight_layout()
plt.show()

"""##Modelo XGBoost
Cria√ß√£o, treinamento e avalia√ß√£o do modelo XGBoost. O mesmo conjunto de variaveis, classe alvo, splits de treino/testes e m√©tricas de avalia√ß√£o utilizados no processo do Random Forest foram utilizados neste processo.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold, cross_val_predict

# Divis√£o entre treino e teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Definir o modelo com balanceamento
model = XGBClassifier(scale_pos_weight=5.65, eval_metric='logloss')

# Treinamento do modelo
model.fit(X_train, y_train)

# Previs√£o
y_pred = model.predict(X_test)

# Matriz de Confus√£o
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title("Matriz de Confus√£o - XGBoost")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.show()
print("\nRelat√≥rio de Classifica√ß√£o:\n", classification_report(y_test, y_pred))

"""##Interpreta√ß√£o dos Resultados do Modelo XGBoost
###Matriz de Confus√£o
- Verdadeiros Negativos (TN): 357 ‚Äî Clientes corretamente classificados como n√£o responsivos.

- Falsos Positivos (FP): 20 ‚Äî Clientes previstos como responsivos, mas que n√£o responderam.

- Falsos Negativos (FN): 40 ‚Äî Clientes que responderiam, mas o modelo n√£o identificou.

- Verdadeiros Positivos (TP): 27 ‚Äî Clientes corretamente classificados como responsivos.

###Outras M√©tricas
- Acur√°cia geral: 0.86 ‚Äî O modelo acerta 86% das previs√µes.

- Precision da classe 1 (0.57): Quando o modelo diz que o cliente vai responder, ele est√° certo em 57% dos casos.

- Recall da classe 1 (0.40): O modelo detecta 40% dos clientes que realmente responderiam ‚Äî um avan√ßo sobre os 31% anteriores.

- F1-score da classe 1 (0.47): Melhor que a regress√£o, indicando um equil√≠brio mais promissor entre precision e recall para a classe 1.

##Modelo Regress√£o Log√≠stica (com escalonamento)
Cria√ß√£o, treinamento e avalia√ß√£o do modelo de Regress√£o Log√≠stica. O mesmo conjunto de variaveis, classe alvo, splits de treino/testes e m√©tricas de avalia√ß√£o utilizados nos processos do Random Forest e XGBoost foram utilizados neste processo.
"""

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

# Sele√ß√£o de Features
selected_features = [
    'AcceptedCmp5', 'AcceptedCmp1', 'Total_Spent', 'AcceptedCmp3',
    'MntWines', 'MntMeatProducts', 'NumCatalogPurchases',
    'AcceptedCmp4', 'Customer_Days', 'AcceptedCmp2',
    'NumWebPurchases', 'MntGoldProds'
]



# Dados de entrada (features) e alvo (response)
X_selected = df[selected_features]
y = df['Response']

# Pipeline: escala os dados antes de aplicar regress√£o log√≠stica
model = Pipeline([
    ('scaler', StandardScaler()),
    ('logreg', LogisticRegression(class_weight='balanced', solver='saga', max_iter=2000, random_state=42))
])

# Treinamento
model.fit(X_train, y_train)

# Predi√ß√£o
y_pred = model.predict(X_test)

# Avalia√ß√£o
print("Relat√≥rio de Classifica√ß√£o:\n")
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
y_pred_cv = cross_val_predict(model, X_selected, y, cv=skf)

print(classification_report(y, y_pred_cv))

# Matriz de Confus√£o
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title("Matriz de Confus√£o - Regress√£o Log√≠stica (com escalonamento)")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.show()

"""##Interpreta√ß√£o dos Resultados da Regress√£o Log√≠stica (com escalonamento)
###Matriz de Confus√£o
- Verdadeiros Negativos (TN): 316 ‚Äî Clientes corretamente classificados como n√£o responsivos.

- Falsos Positivos (FP): 61 ‚Äî Clientes previstos como responsivos, mas que n√£o responderam.

- Falsos Negativos (FN): 26 ‚Äî Clientes que responderiam, mas o modelo n√£o identificou.

- Verdadeiros Positivos (TP): 41 ‚Äî Clientes corretamente classificados como responsivos.

###Outras M√©tricas
- Acur√°cia geral: 0.78 ‚Äî O modelo acerta 78% das previs√µes.

- Recall da classe 1 (0.66): Capacidade de identificar quem realmente respondeu ‚Äî melhor que os modelos anteriores.

- Precision da classe 1 (0.37): O modelo ainda comete erros ao prever que o cliente vai responder ‚Äî quase 63% dessas previs√µes est√£o erradas.

- F1-score da classe 1 (0.47): Indica um equil√≠brio moderado entre precis√£o e cobertura para os clientes que responderam.

# Conclus√£o: Sele√ß√£o do Modelo para Campanha de Marketing de Vinhos

## üìä Comparativo de Desempenho

| M√©trica               | Random Forest | XGBoost | Regress√£o Log√≠stica |
|-----------------------|---------------|---------|----------------------|
| **Acur√°cia Geral**    | 89%           | 86%     | 78%                  |
| **Recall (Classe 1)** | 31%           | 40%     | 66%                  |
| **Precision (Classe 1)** | 84%       | 57%     | 37%                  |
| **F1-Score (Classe 1)** | 0.46      | 0.47    | 0.47                 |

## üéØ Recomenda√ß√£o por Cen√°rio

### 1. Prioridade: Efici√™ncia de Custo (Minimizar Falsos Positivos)
- **Modelo Ideal:** Random Forest  
- **Vantagem:** Alta precis√£o (84%) - quando prev√™ compra, est√° quase sempre certo  
- **Cen√°rio Ideal:** Campanhas com alto custo por contato  
- **Desvantagem:** Perde 69% dos clientes potenciais  

### 2. Prioridade: Maximizar Convers√µes
- **Modelo Ideal:** Regress√£o Log√≠stica  
- **Vantagem:** Alto recall (66%) - captura a maioria dos compradores reais  
- **Cen√°rio Ideal:** Campanhas digitais de baixo custo (ex.: e-mail marketing)  
- **Desvantagem:** 63% das previs√µes positivas est√£o erradas  

### 3. Solu√ß√£o Balanceada
- **Modelo Ideal:** XGBoost  
- **Vantagem:** Equil√≠brio entre precis√£o e recall  
- **Cen√°rio Ideal:** Campanhas com or√ßamento moderado
"""